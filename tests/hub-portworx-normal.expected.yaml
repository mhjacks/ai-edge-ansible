---
# Source: portworx/templates/storageclass/rbac/serviceAccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: portworx-sc-sa
  namespace: portworx
  annotations:
    argocd.argoproj.io/sync-hook: "PreSync"
    argocd.argoproj.io/sync-wave: "-10"
---
# Source: portworx/templates/storageclass/portworx-rwx.yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  annotations:
    argocd.argoproj.io/sync-wave: "4"
  name: px-csi-db-shared
parameters:
  io_profile: db_remote
  repl: "3"
  sharedv4: "true"
  sharedv4_svc_type: "ClusterIP"
provisioner: pxd.portworx.com
reclaimPolicy: Delete
volumeBindingMode: Immediate
allowVolumeExpansion: true
---
# Source: portworx/templates/storageclass/rbac/clusterrole.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
    argocd.argoproj.io/sync-wave: "-15"
  name: portworx-sc-clusterrole
rules:
- apiGroups: ["*"]
  resources: ['pods','storageclusters']
  verbs: ['get','list']
---
# Source: portworx/templates/storageclass/rbac/clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: portworx-sc-clusterrolebinding
  annotations:
    argocd.argoproj.io/hook: PreSync
    argocd.argoproj.io/sync-wave: "-15"
subjects:
- kind: ServiceAccount
  name: portworx-sc-sa
  namespace: portworx
  apiGroup: ""
roleRef:
  kind: ClusterRole
  name: portworx-sc-clusterrole
  apiGroup: rbac.authorization.k8s.io
---
# Source: portworx/templates/storageclass/rbac/role-ns.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  annotations:
    argocd.argoproj.io/hook: PreSync
    argocd.argoproj.io/sync-wave: "-15"
  namespace: portworx 
  name: portworx-sc-ns-role
rules:
- apiGroups: ["*"]
  resources: ["*"]
  verbs: ["*"]
---
# Source: portworx/templates/storageclass/rbac/rolebinding-ns.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: portworx-sc-ns-rolebinding
  annotations:
    argocd.argoproj.io/hook: PreSync
    argocd.argoproj.io/sync-wave: "-15"
subjects:
- kind: ServiceAccount
  name: portworx-sc-sa
  namespace: portworx
  apiGroup: ""
roleRef:
  kind: Role
  name: portworx-sc-ns-role
  apiGroup: rbac.authorization.k8s.io
---
# Source: portworx/templates/storageclass/wait-for-pxe.yaml
apiVersion: batch/v1
kind: Job
metadata:
  annotations:
    argocd.argoproj.io/sync-wave: "3"
  name: job-wait-for-portworx
  namespace: portworx
spec:
  template:
    spec:
      containers:
      - image: quay.io/hybridcloudpatterns/utility-container
        command:
        - /bin/bash
        - -x
        - -c
        - |
          stc_status=$(oc get stc -n portworx | grep -E "Online|Running" | wc -l)
          until [ "$stc_status" -eq "1" ];
          do
            echo "Portworx storagecluster not yet online"
            sleep 10
            stc_status=$(oc get stc -n portworx | grep -E "Online|Running" | wc -l)
          done
          echo "Portworx storagecluster online, waiting for all containers to start"
          num_px_pods=$(oc get pod -l name=portworx -n portworx --no-headers | wc -l)
          while [ 1 ];
          do
            num_px_pods_ready=$(oc get pod -l name=portworx -n portworx |grep -P '\s+([1-9]+[\d]*)\/\1\s+' | wc -l)
            if [ "$num_px_pods_ready" -eq "$num_px_pods" ]; then
              echo "Portworx is ready, $num_px_pods_ready of $num_px_pods pods running 2/2"
              exit 0
            fi
            echo "Portworx is not yet ready, $num_px_pods_ready of $num_px_pods pods running 2/2"
            sleep 15
          done
        name: wait-for-portworx-ready
      dnsPolicy: ClusterFirst
      restartPolicy: Never
      serviceAccount: portworx-sc-sa
      serviceAccountName: portworx-sc-sa
      terminationGracePeriodSeconds: 600
---
# Source: portworx/templates/portworx-storagecluster.yaml
apiVersion: core.libopenstorage.org/v1
kind: StorageCluster
metadata:
  name: px-cluster-region
  namespace: portworx
  annotations:
    argocd.argoproj.io/sync-wave: "3"
    portworx.io/is-openshift: "true"
    portworx.com/install-source: helm-rhmcgo
    portworx.com/helm-vars: chart="portworx-0.0.1",cloudProvider="map[storageClass:default-rwo]" ,csi="true" ,deleteStrategy="UninstallAndWipe" ,envVars="none" ,global="map[clusterDomain:region.example.com clusterPlatform:aws clusterVersion:4.12 hub:map[provider:aws storageClassName:gp3] hubClusterDomain:apps.hub.example.com localClusterDomain:apps.region.example.com multiClusterTarget:all namespace:pattern-namespace options:map[installPlanApproval:Automatic syncPolicy:Automatic useCSV:false] pattern:mypattern repoURL:https://github.com/pattern-clone/mypattern]" ,internalKVDB="true" ,main="map[clusterGroupName:hub git:map[repoURL:https://github.com/pattern-clone/mypattern revision:main]]" ,namespace="portworx" ,network="map[dataInterface:none managementInterface:none]" ,pxnamespace="portworx" ,repo="map[dr:docker.io/portworx enterprise:docker.io/portworx]" ,secretType="k8s" ,secrets="map[AWSsecretName:aws-creds AWSsecretNamespace:kube-system]" ,storage="map[drives:type=gp2,size=20 journalDevice:<nil> kvdbDrives:type=gp2,size=150 maxStorageNodesPerZone:1 usedrivesAndPartitions:false usefileSystemDrive:false]" ,versions="map[autoPilot:1.3.7 enterprise:2.13.4 ociMon:2.13.4 stork:23.4.0]" 
spec:
  deleteStrategy:
    type: UninstallAndWipe
  env:
    # TODO: Change this hardcoded image path to an ECR registry path with px-enterprise image (PWX-27961)
    - name: PX_IMAGE
      value: docker.io/portworx/px-enterprise:2.13.0
    - name: PX_NAMESPACE
      value: portworx
  image: "portworx/oci-monitor:2.13.4"
  imagePullPolicy: Always
  kvdb:
    internal: true
  cloudStorage:
    deviceSpecs:
    - type=gp2,size=20
    journalDeviceSpec: auto
    kvdbDeviceSpec: type=gp2,size=150
    maxStorageNodesPerZone: 1
  secretsProvider: k8s
  stork:
    enabled: true
    args:
      webhook-controller: "true"
    image: "openstorage/stork:23.4.0"
  autopilot:
    enabled: true
    image: "portworx/autopilot:1.3.7"
  csi:
    enabled: true
